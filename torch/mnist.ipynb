{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f720375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8831eb73-1913-45f9-8fa0-714143d55df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Index: 0\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4060 Laptop GPU', major=8, minor=9, total_memory=8187MB, multi_processor_count=24)\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Device Index:\", torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_properties(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77878949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"../data/mnist_train.csv\"):\n",
    "    !curl -O https://pjreddie.com/media/files/mnist_train.csv\n",
    "\n",
    "if not os.path.exists(\"../data/mnist_test.csv\"):\n",
    "    !curl -O https://pjreddie.com/media/files/mnist_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17866ca5-0d4e-4e8b-b5ab-bef4ba79b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(250228)\n",
    "torch.cuda.manual_seed_all(250228)\n",
    "\n",
    "def read_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path, header=None).values\n",
    "    x = torch.tensor(df[:, 1:] / 255.0, dtype=torch.float32)\n",
    "    y = torch.tensor(df[:, 0], dtype=torch.long)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = read_dataset(\"../data/mnist_train.csv\")\n",
    "x_test, y_test = read_dataset(\"../data/mnist_test.csv\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "lr = 0.03\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 320)\n",
    "        self.fc2 = nn.Linear(320, 160)\n",
    "        self.fc3 = nn.Linear(160, 10)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # He Normalization: https://paperswithcode.com/method/he-initialization\n",
    "                init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "# model = torch.compile(model) # add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5f04b1-2ca0-4eae-8061-e5581110c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 2002ms train loss: 0.444774 train accuracy: 0.878869 val loss: 0.268687 val accuracy: 0.921474\n",
      "epoch 2: 1656ms train loss: 0.225104 train accuracy: 0.935832 val loss: 0.203643 val accuracy: 0.939103\n",
      "epoch 3: 1854ms train loss: 0.175538 train accuracy: 0.949606 val loss: 0.166154 val accuracy: 0.949720\n",
      "epoch 4: 2040ms train loss: 0.144439 train accuracy: 0.958261 val loss: 0.141514 val accuracy: 0.957632\n",
      "epoch 5: 1712ms train loss: 0.122692 train accuracy: 0.964631 val loss: 0.125060 val accuracy: 0.963341\n",
      "epoch 6: 1931ms train loss: 0.106329 train accuracy: 0.969400 val loss: 0.113687 val accuracy: 0.966346\n",
      "epoch 7: 2121ms train loss: 0.093335 train accuracy: 0.973152 val loss: 0.105405 val accuracy: 0.968450\n",
      "epoch 8: 1898ms train loss: 0.082669 train accuracy: 0.976638 val loss: 0.098768 val accuracy: 0.971154\n",
      "epoch 9: 1771ms train loss: 0.073775 train accuracy: 0.979439 val loss: 0.093778 val accuracy: 0.972756\n",
      "epoch 10: 1912ms train loss: 0.066209 train accuracy: 0.981590 val loss: 0.090322 val accuracy: 0.972456\n",
      "epoch 11: 2015ms train loss: 0.059720 train accuracy: 0.983991 val loss: 0.087437 val accuracy: 0.973057\n",
      "epoch 12: 2233ms train loss: 0.054122 train accuracy: 0.985626 val loss: 0.084907 val accuracy: 0.973458\n",
      "epoch 13: 2048ms train loss: 0.049213 train accuracy: 0.987327 val loss: 0.082812 val accuracy: 0.973458\n",
      "epoch 14: 2027ms train loss: 0.044830 train accuracy: 0.988661 val loss: 0.081212 val accuracy: 0.973758\n",
      "epoch 15: 2219ms train loss: 0.040953 train accuracy: 0.989745 val loss: 0.079568 val accuracy: 0.974659\n",
      "epoch 16: 2120ms train loss: 0.037442 train accuracy: 0.990878 val loss: 0.078514 val accuracy: 0.974559\n",
      "epoch 17: 2077ms train loss: 0.034263 train accuracy: 0.992029 val loss: 0.077291 val accuracy: 0.974760\n",
      "epoch 18: 1757ms train loss: 0.031367 train accuracy: 0.992846 val loss: 0.076726 val accuracy: 0.975060\n",
      "epoch 19: 2382ms train loss: 0.028763 train accuracy: 0.993763 val loss: 0.076208 val accuracy: 0.975661\n",
      "epoch 20: 2070ms train loss: 0.026405 train accuracy: 0.994514 val loss: 0.075452 val accuracy: 0.976062\n",
      "epoch 21: 2092ms train loss: 0.024252 train accuracy: 0.995331 val loss: 0.074933 val accuracy: 0.976062\n",
      "epoch 22: 2126ms train loss: 0.022308 train accuracy: 0.995981 val loss: 0.074660 val accuracy: 0.976362\n",
      "epoch 23: 1700ms train loss: 0.020554 train accuracy: 0.996448 val loss: 0.074100 val accuracy: 0.977264\n",
      "epoch 24: 1840ms train loss: 0.018964 train accuracy: 0.996982 val loss: 0.073753 val accuracy: 0.977764\n",
      "epoch 25: 1828ms train loss: 0.017495 train accuracy: 0.997432 val loss: 0.073523 val accuracy: 0.977764\n",
      "epoch 26: 1806ms train loss: 0.016175 train accuracy: 0.997682 val loss: 0.073409 val accuracy: 0.977764\n",
      "epoch 27: 2038ms train loss: 0.014966 train accuracy: 0.998082 val loss: 0.073220 val accuracy: 0.978165\n",
      "epoch 28: 1814ms train loss: 0.013867 train accuracy: 0.998382 val loss: 0.073146 val accuracy: 0.977865\n",
      "epoch 29: 1894ms train loss: 0.012861 train accuracy: 0.998566 val loss: 0.072934 val accuracy: 0.977865\n",
      "epoch 30: 1857ms train loss: 0.011958 train accuracy: 0.998683 val loss: 0.072794 val accuracy: 0.977764\n",
      "Total Training Time: 58839ms\n",
      "1961ms per epoch\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "training_time = 0.0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_start = time.time()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_cnt = 0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        _, pred = torch.max(y_hat, 1)\n",
    "        train_cnt += y.size(0)\n",
    "        train_correct += (pred == y).sum().item()\n",
    "\n",
    "    epoch_time = (time.time() - epoch_start) * 1000  # ms\n",
    "    training_time += epoch_time\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            val_loss += loss.item() * X.size(0)\n",
    "            _, pred = torch.max(y_hat, 1)\n",
    "            val_cnt += y.size(0)\n",
    "            val_correct += (pred == y).sum().item()\n",
    "\n",
    "    train_acc   = train_correct / train_cnt\n",
    "    val_acc     = val_correct / val_cnt\n",
    "    train_loss  /= train_cnt\n",
    "    val_loss    /= val_cnt\n",
    "    \n",
    "    print(f\"epoch {epoch}: {epoch_time:.0f}ms \"\n",
    "          f\"train loss: {train_loss:.6f} \"\n",
    "          f\"train accuracy: {train_acc:.6f} \"\n",
    "          f\"val loss: {val_loss:.6f} \"\n",
    "          f\"val accuracy: {val_acc:.6f}\"\n",
    "    )\n",
    "\n",
    "print(f\"Total Training Time: {training_time:.0f}ms\")\n",
    "print(f\"{training_time / 30:.0f}ms per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0005d7-e20d-4855-a003-6745a375d9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
